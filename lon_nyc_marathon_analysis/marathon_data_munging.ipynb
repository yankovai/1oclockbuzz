{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.core.pylabtools import figsize\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "These will be used to wrangle the marathon data into a form ripe for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_time_to_h(time):\n",
    "    \"\"\"Convert marathon format time (hh:mm:ss) to hours\"\"\"\n",
    "    \n",
    "    try:\n",
    "        time = map(int, time.split(':'))\n",
    "        time_s = time[0] + time[1]/60. + time[2]/3600.\n",
    "    except (ValueError, AttributeError):\n",
    "        time_s = None\n",
    "    \n",
    "    return(time_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_lon_runner_field(runner):\n",
    "    \"\"\"\n",
    "    Outputs a runner name and representative country from the \n",
    "    London Marathon runner field.\n",
    "    \"\"\"\n",
    "    fields = re.findall(\"[a-z]+\", runner.lower())\n",
    "    country = fields[-1]\n",
    "    name = ' '.join(fields[:-1])\n",
    "    \n",
    "    return(pd.Series({\"name\": name, \"country\": country}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_age_field(agegender):\n",
    "    \"\"\"\n",
    "    Splits concatenated age field in raw NYC marathon data into independent \n",
    "    age, gender, and age category fields. \n",
    "    \"\"\"\n",
    "    \n",
    "    age, gender = int(agegender[:-1]), agegender[-1].lower()\n",
    "    return (pd.Series({'age': age, 'gender': gender}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## London Marathon Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2015 London Marathon results could be easily scraped. I just built a simple scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_london_marathon_data():\n",
    "    \"\"\"Scrape raw London Marathon 2015 results from official site\"\"\"\n",
    "    \n",
    "    url = \"http://results-2015.virginmoneylondonmarathon.com/2015/?page={0}&event=MAS&num_results=1000&pid=search&search%5Bsex%5D=%25&search%5Bnation%5D=%25&search_sort=name\"\n",
    "\n",
    "    for page_num in range(1, 45): \n",
    "        runner_data = urllib2.urlopen(url.format(page_num))    \n",
    "        file_str = u\"london_marathon_result_{0}.txt\".format(page_num)\n",
    "        with open(file_str, 'wb') as txt_file:\n",
    "            txt_file.write(runner_data.read())\n",
    "\n",
    "    return \n",
    "\n",
    "# get_london_marathon_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tabularize_lon_data():\n",
    "    \"\"\"Turn all london marathon files into one dataframe after processing html\"\"\"\n",
    "    \n",
    "    file_str = \"london_marathon_result_{0}.txt\"\n",
    "    rows = []\n",
    "\n",
    "    for page_num in range(1, 45): \n",
    "        with open(file_str.format(page_num), \"rb\") as txt_file:\n",
    "            run_data = txt_file.read()\n",
    "\n",
    "        soup = BeautifulSoup(run_data, \"html5lib\")\n",
    "        table = soup.find(\"table\", attrs={\"class\": \"list-table\"})\n",
    "\n",
    "        for tr in table.find(\"tbody\").find_all(\"tr\"):\n",
    "            row = [td.get_text() for td in tr.find_all(\"td\")]\n",
    "            rows.append(row)\n",
    "\n",
    "    lon_data = pd.DataFrame(rows, columns=['0', '1', '2', 'runner', 'club', 'runner_num', 'age_cat', 'half', 'finish', '3'])\n",
    "    \n",
    "    return (lon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lon_data = tabularize_lon_data()\n",
    "\n",
    "assert lon_data.shape[0] > 40000, \"Missing a few rows?\"\n",
    "\n",
    "# Clean up dataframe \n",
    "lon_data.drop(['0', '1', '2', '3', 'club', 'runner_num'], axis=1, inplace=True)\n",
    "lon_data['13.1_mi'] = lon_data.half.apply(convert_time_to_h)\n",
    "lon_data['26.2_mi'] = lon_data.finish.apply(convert_time_to_h)\n",
    "lon_data = lon_data.join(lon_data.runner.apply(process_lon_runner_field))\n",
    "lon_data = lon_data[['name', 'country', 'age_cat', '13.1_mi', '26.2_mi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'45-49' u'18-39' u'55-59' u'40-44' u'50-54' u'65-69' u'60-64' u'' u'70+']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>13.1_mi</th>\n",
       "      <th>26.2_mi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43744</th>\n",
       "      <td>shekarchi dan</td>\n",
       "      <td>gbr</td>\n",
       "      <td>18-39</td>\n",
       "      <td>1.874722</td>\n",
       "      <td>3.778611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43745</th>\n",
       "      <td>de isidro serrano jes s antonio</td>\n",
       "      <td>esp</td>\n",
       "      <td>45-49</td>\n",
       "      <td>1.653056</td>\n",
       "      <td>3.403056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43746</th>\n",
       "      <td>moraleda menendez jos luis</td>\n",
       "      <td>esp</td>\n",
       "      <td>55-59</td>\n",
       "      <td>2.017778</td>\n",
       "      <td>4.018889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43747</th>\n",
       "      <td>naor costa martin</td>\n",
       "      <td>esp</td>\n",
       "      <td>40-44</td>\n",
       "      <td>1.847222</td>\n",
       "      <td>3.657778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43748</th>\n",
       "      <td>pata franco jesus antonio</td>\n",
       "      <td>esp</td>\n",
       "      <td>50-54</td>\n",
       "      <td>1.655556</td>\n",
       "      <td>3.462222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name country age_cat   13.1_mi   26.2_mi\n",
       "43744                    shekarchi dan     gbr   18-39  1.874722  3.778611\n",
       "43745  de isidro serrano jes s antonio     esp   45-49  1.653056  3.403056\n",
       "43746       moraleda menendez jos luis     esp   55-59  2.017778  4.018889\n",
       "43747                naor costa martin     esp   40-44  1.847222  3.657778\n",
       "43748        pata franco jesus antonio     esp   50-54  1.655556  3.462222"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create same age categories in NYC Marathon data for comparison\n",
    "print (lon_data.age_cat.unique())\n",
    "lon_data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle London marathon data for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lon_data.to_pickle(\"london_marathon_2015_processed.pickle\")\n",
    "lon_data.to_csv(\"london_marathon_2015_processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## NYC Marathon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tabularize_nyc_data():\n",
    "    \"\"\"\n",
    "    Read all NYC Marathon data files and output a pandas dataframe \n",
    "    \"\"\"\n",
    "\n",
    "    nyc_data_filenames = [f for f in os.listdir(\".\") if \"nyc_marathon_ages\" in f]\n",
    "\n",
    "    # Relevant columns to the analysis but they're name named properly\n",
    "    cols_rel = ['First Name', 'Last Name', 'Age', 'State/Country', 'FinishTime', \n",
    "                '5 km', '10 km', '15 km', '20 km', '13.1 mi', '25 km', '30 km', '35 km', '40 km']\n",
    "    cols_names = ['first_name', 'last_name', 'agegender', 'state', 'country', 'finish_time',\n",
    "                  '5 km', '10 km', '15 km', '20 km', '13.1 mi', '25 km', '30 km', '35 km']\n",
    "\n",
    "    nyc_data = pd.DataFrame()\n",
    "    for nyc_data_filename in nyc_data_filenames:\n",
    "        data = pd.read_csv(nyc_data_filename)\n",
    "        data = data[cols_rel]\n",
    "        data.columns = cols_names\n",
    "        data.dropna(subset=['first_name'], inplace=True)\n",
    "        nyc_data = pd.concat([nyc_data, data], ignore_index=True)\n",
    "\n",
    "    assert nyc_data.shape[0] > 40000, \"Missing some rows?\"\n",
    "    \n",
    "    return (nyc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nyc_data = tabularize_nyc_data()\n",
    "nyc_data['name'] = nyc_data.last_name.str.lower() + ' ' + nyc_data.first_name.str.lower()\n",
    "nyc_data['country'] = nyc_data.country.str.lower()\n",
    "nyc_data['state'] = nyc_data.state.str.lower()\n",
    "nyc_data['26.2_mi'] = nyc_data.finish_time.apply(convert_time_to_h)\n",
    "nyc_data['5_km'] = nyc_data[\"5 km\"].apply(convert_time_to_h)\n",
    "nyc_data['10_km'] = nyc_data[\"10 km\"].apply(convert_time_to_h)\n",
    "nyc_data['15_km'] = nyc_data[\"15 km\"].apply(convert_time_to_h)\n",
    "nyc_data['20_km'] = nyc_data[\"20 km\"].apply(convert_time_to_h)\n",
    "nyc_data['13.1_mi'] = nyc_data[\"13.1 mi\"].apply(convert_time_to_h)\n",
    "nyc_data['25_km'] = nyc_data[\"25 km\"].apply(convert_time_to_h)\n",
    "nyc_data['30_km'] = nyc_data[\"30 km\"].apply(convert_time_to_h)\n",
    "nyc_data['35_km'] = nyc_data[\"35 km\"].apply(convert_time_to_h)\n",
    "nyc_data = nyc_data.join(nyc_data.agegender.apply(split_age_field))\n",
    "nyc_data = nyc_data[['name', 'state', 'country', 'age', 'gender', \n",
    "                     '26.2_mi', '5_km', '10_km', '15_km', '20_km', '13.1_mi',\n",
    "                     '25_km', '30_km', '35_km']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>26.2_mi</th>\n",
       "      <th>5_km</th>\n",
       "      <th>10_km</th>\n",
       "      <th>15_km</th>\n",
       "      <th>20_km</th>\n",
       "      <th>13.1_mi</th>\n",
       "      <th>25_km</th>\n",
       "      <th>30_km</th>\n",
       "      <th>35_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49457</th>\n",
       "      <td>van der veeken clasina</td>\n",
       "      <td>no</td>\n",
       "      <td>nzl</td>\n",
       "      <td>84</td>\n",
       "      <td>f</td>\n",
       "      <td>6.711944</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>1.538889</td>\n",
       "      <td>2.304722</td>\n",
       "      <td>3.092222</td>\n",
       "      <td>3.269722</td>\n",
       "      <td>3.895833</td>\n",
       "      <td>4.685833</td>\n",
       "      <td>5.514167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49458</th>\n",
       "      <td>roest-bomers agnes</td>\n",
       "      <td>nl</td>\n",
       "      <td>ned</td>\n",
       "      <td>84</td>\n",
       "      <td>f</td>\n",
       "      <td>5.673056</td>\n",
       "      <td>0.576667</td>\n",
       "      <td>1.175000</td>\n",
       "      <td>1.790833</td>\n",
       "      <td>2.438056</td>\n",
       "      <td>2.582778</td>\n",
       "      <td>3.181111</td>\n",
       "      <td>3.870556</td>\n",
       "      <td>4.591667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49459</th>\n",
       "      <td>takahashi yoshiko</td>\n",
       "      <td>ny</td>\n",
       "      <td>jpn</td>\n",
       "      <td>80</td>\n",
       "      <td>f</td>\n",
       "      <td>5.678889</td>\n",
       "      <td>0.660556</td>\n",
       "      <td>1.276389</td>\n",
       "      <td>1.907500</td>\n",
       "      <td>2.543056</td>\n",
       "      <td>2.686389</td>\n",
       "      <td>3.220833</td>\n",
       "      <td>3.904444</td>\n",
       "      <td>4.653889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49460</th>\n",
       "      <td>bedard ginette</td>\n",
       "      <td>ny</td>\n",
       "      <td>usa</td>\n",
       "      <td>82</td>\n",
       "      <td>f</td>\n",
       "      <td>5.329444</td>\n",
       "      <td>0.559444</td>\n",
       "      <td>1.134444</td>\n",
       "      <td>1.711944</td>\n",
       "      <td>2.327500</td>\n",
       "      <td>2.472500</td>\n",
       "      <td>2.989167</td>\n",
       "      <td>3.632778</td>\n",
       "      <td>4.333611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49461</th>\n",
       "      <td>monaco marcia</td>\n",
       "      <td>ny</td>\n",
       "      <td>usa</td>\n",
       "      <td>83</td>\n",
       "      <td>f</td>\n",
       "      <td>10.364444</td>\n",
       "      <td>1.107222</td>\n",
       "      <td>2.249722</td>\n",
       "      <td>3.646667</td>\n",
       "      <td>5.263333</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>6.703611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name state country  age gender    26.2_mi      5_km  \\\n",
       "49457  van der veeken clasina    no     nzl   84      f   6.711944  0.780000   \n",
       "49458      roest-bomers agnes    nl     ned   84      f   5.673056  0.576667   \n",
       "49459       takahashi yoshiko    ny     jpn   80      f   5.678889  0.660556   \n",
       "49460          bedard ginette    ny     usa   82      f   5.329444  0.559444   \n",
       "49461           monaco marcia    ny     usa   83      f  10.364444  1.107222   \n",
       "\n",
       "          10_km     15_km     20_km   13.1_mi     25_km     30_km     35_km  \n",
       "49457  1.538889  2.304722  3.092222  3.269722  3.895833  4.685833  5.514167  \n",
       "49458  1.175000  1.790833  2.438056  2.582778  3.181111  3.870556  4.591667  \n",
       "49459  1.276389  1.907500  2.543056  2.686389  3.220833  3.904444  4.653889  \n",
       "49460  1.134444  1.711944  2.327500  2.472500  2.989167  3.632778  4.333611  \n",
       "49461  2.249722  3.646667  5.263333  5.565000  6.703611       NaN       NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle NYC 2015 Marathon data for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nyc_data.to_pickle(\"nyc_marathon_2015_processed.pickle\")\n",
    "nyc_data.to_csv(\"nyc_marathon_2015_processed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
