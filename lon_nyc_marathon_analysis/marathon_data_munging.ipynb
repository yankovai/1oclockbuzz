{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.pylabtools import figsize\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "These will be used to wrangle the marathon data into a form ripe for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_time_to_h(time):\n",
    "    \"\"\"Convert marathon format time (hh:mm:ss) to hours\"\"\"\n",
    "    \n",
    "    try:\n",
    "        time = map(int, time.split(':'))\n",
    "        time_s = time[0] + time[1]/60. + time[2]/3600.\n",
    "    except (ValueError, AttributeError):\n",
    "        time_s = None\n",
    "    \n",
    "    return(time_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_lon_runner_field(runner):\n",
    "    \"\"\"\n",
    "    Outputs a runner name and representative country from the \n",
    "    London Marathon runner field.\n",
    "    \"\"\"\n",
    "    fields = re.findall(\"[a-z]+\", runner.lower())\n",
    "    country = fields[-1]\n",
    "    name = ' '.join(fields[:-1])\n",
    "    \n",
    "    return(pd.Series({\"name\": name, \"country\": country}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_age_field(agegender):\n",
    "    \"\"\"\n",
    "    Splits concatenated age field in raw NYC marathon data into independent \n",
    "    age, gender, and age category fields. \n",
    "    \"\"\"\n",
    "    \n",
    "    age, gender = int(agegender[:-1]), agegender[-1].lower()\n",
    "    return (pd.Series({'age': age, 'gender': gender}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## London Marathon Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2015 London Marathon results could be easily scraped. I just built a simple scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_london_marathon_data():\n",
    "    \"\"\"Scrape raw London Marathon 2015 results from official site\"\"\"\n",
    "    \n",
    "    url = \"http://results-2015.virginmoneylondonmarathon.com/2015/?page={0}&event=MAS&num_results=1000&pid=search&search%5Bsex%5D=%25&search%5Bnation%5D=%25&search_sort=name\"\n",
    "\n",
    "    for page_num in range(1, 45): \n",
    "        runner_data = urllib2.urlopen(url.format(page_num))    \n",
    "        file_str = u\"london_marathon_result_{0}.txt\".format(page_num)\n",
    "        with open(file_str, 'wb') as txt_file:\n",
    "            txt_file.write(runner_data.read())\n",
    "\n",
    "    return \n",
    "\n",
    "# get_london_marathon_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tabularize_lon_data():\n",
    "    \"\"\"Turn all london marathon files into one dataframe after processing html\"\"\"\n",
    "    \n",
    "    file_str = \"london_marathon_result_{0}.txt\"\n",
    "    rows = []\n",
    "\n",
    "    for page_num in range(1, 45): \n",
    "        with open(file_str.format(page_num), \"rb\") as txt_file:\n",
    "            run_data = txt_file.read()\n",
    "\n",
    "        soup = BeautifulSoup(run_data, \"html5lib\")\n",
    "        table = soup.find(\"table\", attrs={\"class\": \"list-table\"})\n",
    "\n",
    "        for tr in table.find(\"tbody\").find_all(\"tr\"):\n",
    "            row = [td.get_text() for td in tr.find_all(\"td\")]\n",
    "            rows.append(row)\n",
    "\n",
    "    lon_data = pd.DataFrame(rows, columns=['0', '1', '2', 'runner', 'club', 'runner_num', 'age_cat', 'half', 'finish', '3'])\n",
    "    \n",
    "    return (lon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lon_data = tabularize_lon_data()\n",
    "\n",
    "assert lon_data.shape[0] > 40000, \"Missing a few rows?\"\n",
    "\n",
    "# Clean up dataframe \n",
    "lon_data.drop(['0', '1', '2', '3', 'club', 'runner_num'], axis=1, inplace=True)\n",
    "lon_data['13.1_mi'] = lon_data.half.apply(convert_time_to_h)\n",
    "lon_data['26.2_mi'] = lon_data.finish.apply(convert_time_to_h)\n",
    "lon_data = lon_data.join(lon_data.runner.apply(process_lon_runner_field))\n",
    "lon_data = lon_data[['name', 'country', 'age_cat', '13.1_mi', '26.2_mi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create same age categories in NYC Marathon data for comparison\n",
    "print (lon_data.age_cat.unique())\n",
    "lon_data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle London marathon data for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lon_data.to_pickle(\"london_marathon_2015_processed.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## NYC Marathon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tabularize_nyc_data():\n",
    "    \"\"\"\n",
    "    Read all NYC Marathon data files and output a pandas dataframe \n",
    "    \"\"\"\n",
    "\n",
    "    nyc_data_filenames = [f for f in os.listdir(\".\") if \"nyc_marathon_ages\" in f]\n",
    "\n",
    "    # Relevant columns to the analysis but they're name named properly\n",
    "    cols_rel = ['First Name', 'Last Name', 'Age', 'State/Country', 'FinishTime', \n",
    "                '5 km', '10 km', '15 km', '20 km', '13.1 mi', '25 km', '30 km', '35 km', '40 km']\n",
    "    cols_names = ['first_name', 'last_name', 'agegender', 'state', 'country', 'finish_time',\n",
    "                  '5 km', '10 km', '15 km', '20 km', '13.1 mi', '25 km', '30 km', '35 km']\n",
    "\n",
    "    nyc_data = pd.DataFrame()\n",
    "    for nyc_data_filename in nyc_data_filenames:\n",
    "        data = pd.read_csv(nyc_data_filename)\n",
    "        data = data[cols_rel]\n",
    "        data.columns = cols_names\n",
    "        data.dropna(subset=['first_name'], inplace=True)\n",
    "        nyc_data = pd.concat([nyc_data, data], ignore_index=True)\n",
    "\n",
    "    assert nyc_data.shape[0] > 40000, \"Missing some rows?\"\n",
    "    \n",
    "    return (nyc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nyc_data = tabularize_nyc_data()\n",
    "nyc_data['name'] = nyc_data.last_name.str.lower() + ' ' + nyc_data.first_name.str.lower()\n",
    "nyc_data['country'] = nyc_data.country.str.lower()\n",
    "nyc_data['state'] = nyc_data.state.str.lower()\n",
    "nyc_data['26.2_mi'] = nyc_data.finish_time.apply(convert_time_to_h)\n",
    "nyc_data['5_km'] = nyc_data[\"5 km\"].apply(convert_time_to_h)\n",
    "nyc_data['10_km'] = nyc_data[\"10 km\"].apply(convert_time_to_h)\n",
    "nyc_data['15_km'] = nyc_data[\"15 km\"].apply(convert_time_to_h)\n",
    "nyc_data['20_km'] = nyc_data[\"20 km\"].apply(convert_time_to_h)\n",
    "nyc_data['13.1_mi'] = nyc_data[\"13.1 mi\"].apply(convert_time_to_h)\n",
    "nyc_data['25_km'] = nyc_data[\"25 km\"].apply(convert_time_to_h)\n",
    "nyc_data['30_km'] = nyc_data[\"30 km\"].apply(convert_time_to_h)\n",
    "nyc_data['35_km'] = nyc_data[\"35 km\"].apply(convert_time_to_h)\n",
    "nyc_data = nyc_data.join(nyc_data.agegender.apply(split_age_field))\n",
    "nyc_data = nyc_data[['name', 'state', 'country', 'age', 'gender', \n",
    "                     '26.2_mi', '5_km', '10_km', '15_km', '20_km', '13.1_mi',\n",
    "                     '25_km', '30_km', '35_km']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle NYC 2015 Marathon data for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nyc_data.to_pickle(\"nyc_marathon_2015_processed.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
